{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "USO8Zx1_azwU"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb  "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSiSt3wtm24N"
      },
      "source": [
        "def final_fun_1(X):\n",
        "\n",
        "  test_data = pd.DataFrame(np.array([X]),columns=['date','store','item','id'])\n",
        "  test_data['date'] = pd.to_datetime(test_data['date'])\n",
        "  test_data = test_data.astype({\"store\": int, \"item\": int, \"id\": float})\n",
        "  test_data['day'] = test_data.date.dt.day\n",
        "  test_data['month'] = test_data.date.dt.month\n",
        "  test_data['year'] = test_data.date.dt.year\n",
        "  test_data['dayofweek'] = test_data.date.dt.dayofweek\n",
        "  store_2018 = pd.read_csv('store_2018.csv',parse_dates=['date'])\n",
        "  store = test_data\n",
        "  store['sales'] = store_2018.loc[(store_2018['date'] == store.loc[0,'date']) & (store_2018['store'] == store.loc[0,'store']) & (store_2018['item'] == store.loc[0,'item'])]['sales']\n",
        "  \n",
        "  store['dayofyear'] = store.date.dt.dayofyear\n",
        "  store['weekofyear'] = store.date.dt.weekofyear\n",
        "  store['weekend_yes'] = store.date.dt.weekday // 4\n",
        "  store['month_start_yes'] = store.date.dt.is_month_start.astype(int)\n",
        "  store['month_end_yes'] = store.date.dt.is_month_end.astype(int)\n",
        "  store['quarter'] = store.date.dt.quarter\n",
        "  store['weekofmonth'] = store['weekofyear'].values // 4.35                                                                                                                                                                               \n",
        "  store['mon_yes'] = np.where(store['dayofweek'] == 0, 1, 0)                                                                                            \n",
        "  store['tue_yes'] = np.where(store['dayofweek'] == 1, 1, 0)                                                                                         \n",
        "  store['wed_yes'] = np.where(store['dayofweek'] == 2, 1, 0)                                                                                         \n",
        "  store['thu_yes'] = np.where(store['dayofweek'] == 3, 1, 0)                                                                                         \n",
        "  store['fri_yes'] = np.where(store['dayofweek'] == 4, 1, 0)                                                                                         \n",
        "  store['sat_yes'] = np.where(store['dayofweek'] == 5, 1, 0)                                                                                         \n",
        "  store['sun_yes'] = np.where(store['dayofweek'] == 6, 1, 0) \n",
        "\n",
        "  exp_time_features = ['dayofweek', 'weekofmonth', 'weekofyear', 'month', 'quarter', 'weekend_yes'] \n",
        "  for exp_item in exp_time_features:\n",
        "    expanding_store = store.groupby(['store', 'item', exp_item])['sales'].expanding().mean().bfill().reset_index()\n",
        "    expanding_store.columns = ['store', 'item', exp_item, 'exp_index', 'exp_'+exp_item]\n",
        "    expanding_store = expanding_store.sort_values(by=['item', 'store', 'exp_index'])\n",
        "    store['exp_'+exp_item] = expanding_store['exp_'+exp_item].values\n",
        "\n",
        "  store.sort_values(by=['item', 'store', 'date'], axis=0, inplace=True)\n",
        "\n",
        "  #Adding Lag values as feature\n",
        "  l = [8,15,22,29,30,31,38,61,67,73,91, 98, 105, 112, 180, 270, 365, 546, 728]                                                                                                                                                                                                                      \n",
        "  for var_l in l:                                                                                                                          \n",
        "    store['l_' + str(var_l)] = store.groupby([\"item\", \"store\"])['sales'].transform(lambda y: y.shift(var_l)) + np.random.normal(scale=0.01, size=(len(store),))  \n",
        "\n",
        "  #Adding Rolling Mean values as feature\n",
        "  r = [8,15,22,29,30,31,38,61,67,73,91, 98, 105, 112, 180, 270, 365, 546, 728]                                                                                                                                                                                                                                                                                                                       \n",
        "  for var_r in r:                                                                                                                    \n",
        "    store['r_' + str(var_r)] = store.groupby([\"item\", \"store\"])['sales'].transform(lambda y: y.shift(1).rolling(window=var_r, min_periods=8, win_type=\"triang\").mean()) + np.random.normal(scale=0.01, size=(len(store),)) \n",
        "\n",
        "  #Adding Exponentially Mean values as feature\n",
        "  ewm_a = [0.95, 0.9, 0.8, 0.7, 0.5,.4,.3,.2,.1]                                             \n",
        "  ewm_l = [8,15,22,29,30,31,38,61,67,73,91, 98, 105, 112, 180, 270, 365, 546, 728]                                                                                                      \n",
        "  for var_a in ewm_a:                                                                                                                      \n",
        "    for var_l in ewm_l:                                                                                                                      \n",
        "      store['ewm_a_' + str(var_a) + \"_l_\" + str(var_l)] = store.groupby([\"item\", \"store\"])['sales'].transform(lambda y: y.shift(var_l).ewm(alpha=var_a).mean()) \n",
        "\n",
        "  store_encoding = pd.get_dummies(store[['store', 'item', 'dayofweek', 'month']], columns=['store', 'item', 'dayofweek', 'month'], dummy_na=True)  \n",
        "  store_final = pd.concat([store, store_encoding], axis=1)                                                                                                          \n",
        "  store_lgbm_columns = [column for column in store_final.columns if column not in ['date', 'id', 'sales', 'year']]                                                                                                            \n",
        "  test = store_final[store_lgbm_columns] \n",
        "                                                                                                                                                                                                                                                                                                                   \n",
        "  model = lgb.Booster(model_file='store_lgbm_model.txt')\n",
        "  store_lgbm_preds = model.predict(test, num_iteration=1500) \n",
        "  store_lgbm_preds_sales = np.round(np.expm1(store_lgbm_preds),0)\n",
        "\n",
        "  return store_lgbm_preds_sales"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#input format to func is 'date,store,item,id'\n",
        "pred1 = final_fun_1(['2018-01-05',2,3,0])"
      ],
      "metadata": {
        "id": "Z67OMnn1kDVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iSZ4Gxil-wj",
        "outputId": "6dfb6180-4a59-479e-e4bc-a40cb3f13d49"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([15.])"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred2 = final_fun_1(['2018-02-07',1,1,0])"
      ],
      "metadata": {
        "id": "KkmVjCopl9sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FB_9FBEJks-F",
        "outputId": "fbd4f23f-8aca-49e1-a92e-455ba75d95e8"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([20.])"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def final_fun_2(X,Y):\n",
        "\n",
        "  test_data = X\n",
        "  target_data = Y\n",
        "\n",
        "  test_data['day'] = test_data.index.day\n",
        "  test_data['month'] = test_data.index.month\n",
        "  test_data['year'] = test_data.index.year\n",
        "  test_data['dayofweek'] = test_data.index.dayofweek\n",
        "  store_2018 = pd.read_csv('store_2018.csv',parse_dates=['date'])\n",
        "  store = test_data\n",
        "  store.reset_index(inplace=True)\n",
        "  store['sales'] = 0\n",
        "\n",
        "  for index,row in store.iterrows():\n",
        "    sales = store_2018.loc[(store_2018['date'] == row['date']) & (store_2018['store'] == row['store']) & (store_2018['item'] == row['item'])]['sales']\n",
        "    store.at[index, 'sales'] = sales\n",
        "  \n",
        "  store['dayofyear'] = store.date.dt.dayofyear\n",
        "  store['weekofyear'] = store.date.dt.weekofyear\n",
        "  store['weekend_yes'] = store.date.dt.weekday // 4\n",
        "  store['month_start_yes'] = store.date.dt.is_month_start.astype(int)\n",
        "  store['month_end_yes'] = store.date.dt.is_month_end.astype(int)\n",
        "  store['quarter'] = store.date.dt.quarter\n",
        "  store['weekofmonth'] = store['weekofyear'].values // 4.35                                                                                                                                                                               \n",
        "  store['mon_yes'] = np.where(store['dayofweek'] == 0, 1, 0)                                                                                            \n",
        "  store['tue_yes'] = np.where(store['dayofweek'] == 1, 1, 0)                                                                                         \n",
        "  store['wed_yes'] = np.where(store['dayofweek'] == 2, 1, 0)                                                                                         \n",
        "  store['thu_yes'] = np.where(store['dayofweek'] == 3, 1, 0)                                                                                         \n",
        "  store['fri_yes'] = np.where(store['dayofweek'] == 4, 1, 0)                                                                                         \n",
        "  store['sat_yes'] = np.where(store['dayofweek'] == 5, 1, 0)                                                                                         \n",
        "  store['sun_yes'] = np.where(store['dayofweek'] == 6, 1, 0) \n",
        "\n",
        "  exp_time_features = ['dayofweek', 'weekofmonth', 'weekofyear', 'month', 'quarter', 'weekend_yes'] \n",
        "  for exp_item in exp_time_features:\n",
        "    expanding_store = store.groupby(['store', 'item', exp_item])['sales'].expanding().mean().bfill().reset_index()\n",
        "    expanding_store.columns = ['store', 'item', exp_item, 'exp_index', 'exp_'+exp_item]\n",
        "    expanding_store = expanding_store.sort_values(by=['item', 'store', 'exp_index'])\n",
        "    store['exp_'+exp_item] = expanding_store['exp_'+exp_item].values\n",
        "\n",
        "  store.sort_values(by=['item', 'store', 'date'], axis=0, inplace=True)\n",
        "\n",
        "  #Adding Lag values as feature\n",
        "  l = [8,15,22,29,30,31,38,61,67,73,91, 98, 105, 112, 180, 270, 365, 546, 728]                                                                                                                                                                                                                      \n",
        "  for var_l in l:                                                                                                                          \n",
        "    store['l_' + str(var_l)] = store.groupby([\"item\", \"store\"])['sales'].transform(lambda y: y.shift(var_l)) + np.random.normal(scale=0.01, size=(len(store),)) \n",
        "\n",
        "  #Adding Rolling Mean values as feature\n",
        "  r = [8,15,22,29,30,31,38,61,67,73,91, 98, 105, 112, 180, 270, 365, 546, 728]                                                                                                                                                                                                                                                                                                                       \n",
        "  for var_r in r:                                                                                                                    \n",
        "    store['r_' + str(var_r)] = store.groupby([\"item\", \"store\"])['sales'].transform(lambda y: y.shift(1).rolling(window=var_r, min_periods=8, win_type=\"triang\").mean()) + np.random.normal(scale=0.01, size=(len(store),)) \n",
        "\n",
        "  #Adding Exponentially Mean values as feature\n",
        "  ewm_a = [0.95, 0.9, 0.8, 0.7, 0.5,.4,.3,.2,.1]                                             \n",
        "  ewm_l = [8,15,22,29,30,31,38,61,67,73,91, 98, 105, 112, 180, 270, 365, 546, 728]                                                                                                      \n",
        "  for var_a in ewm_a:                                                                                                                      \n",
        "    for var_l in ewm_l:                                                                                                                      \n",
        "      store['ewm_a_' + str(var_a) + \"_l_\" + str(var_l)] = store.groupby([\"item\", \"store\"])['sales'].transform(lambda y: y.shift(var_l).ewm(alpha=var_a).mean()) \n",
        "\n",
        "  store_encoding = pd.get_dummies(store[['store', 'item', 'dayofweek', 'month']], columns=['store', 'item', 'dayofweek', 'month'], dummy_na=True)  \n",
        "  store_final = pd.concat([store, store_encoding], axis=1)                                                                                                          \n",
        "  store_lgbm_columns = [column for column in store_final.columns if column not in ['date', 'id', 'sales', 'year']]                                                                                                            \n",
        "  test = store_final[store_lgbm_columns] \n",
        "                                                                                                                                                                                                                                                                                                                   \n",
        "  model = lgb.Booster(model_file='store_lgbm_model.txt')\n",
        "  store_lgbm_preds = model.predict(test, num_iteration=1500) \n",
        "  store_lgbm_preds_sales = np.round(np.expm1(store_lgbm_preds),0)\n",
        "  pred_length = len(store_lgbm_preds_sales)\n",
        "  pred_smape_masked = ~((store_lgbm_preds_sales == 0) & (target_data == 0))\n",
        "  store_lgbm_preds_sales, target_data = store_lgbm_preds_sales[pred_smape_masked], target_data[pred_smape_masked]\n",
        "  pred_smape_num = np.abs(store_lgbm_preds_sales - target_data)\n",
        "  pred_smape_den = np.abs(store_lgbm_preds_sales) + np.abs(target_data)\n",
        "  pred_smape = (200 * np.sum(pred_smape_num / pred_smape_den)) / pred_length\n",
        "\n",
        "  return pred_smape"
      ],
      "metadata": {
        "id": "5N-ukIFpiw5t"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation = pd.read_csv('validation.csv', parse_dates=['date'], index_col=['date'])\n",
        "Y = validation['sales']\n",
        "X = validation.drop(columns=['sales'])"
      ],
      "metadata": {
        "id": "OPcjVNeZmfKQ"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = final_fun_2(X,Y)"
      ],
      "metadata": {
        "id": "XCCEKHVDo20m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SbOcLQhwv9D",
        "outputId": "f764e308-ce71-4bcd-a580-aa58a0c00d7c"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12.90835688572578"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    }
  ]
}